# Configuration file for TravisCI

# We use miniconda for Python so don't need any Python specific tools
language: generic

# Use the container builds so we don't need sudo priviledges
sudo: false

# Only build pushes to the master branch and tags. This avoids the double
# builds than happen when working on a branch instead of a fork.
branches:
    only:
        - master
        # Regex to build tagged commits with version numbers
        - /\d+\.\d+(\.\d+)?(\S*)?$/

# Define environment variables common to all builds
env:
    global:
        # Encrypted variables
        # Github Token for pushing the built HTML (GH_TOKEN)
        #-
        # PyPI password for deploying releases (TWINE_PASSWORD)
        #-
        - TWINE_USERNAME={{ cookiecutter.pypi_username }}
        # The files with the listed requirements to be installed by conda
        - CONDA_REQUIREMENTS=requirements.txt
        - CONDA_REQUIREMENTS_DEV=requirements-dev.txt
        - CONDA_INSTALL_EXTRA="codecov"
        # These variables control which actions are performed in a build
        - DEPLOY_DOCS=false
        - DEPLOY_PYPI=false

# Specify the build configurations. Be sure to only deploy from a single build.
matrix:
    include:
        # Main build to deploy to PyPI and Github pages
        - name: "Linux - Python 3.7 (deploy)"
          os: linux
          env:
              - PYTHON=3.7
              - DEPLOY_DOCS=true
              - DEPLOY_PYPI=true
        - name: "Linux - Python 3.6"
          os: linux
          env:
              - PYTHON=3.6

# Setup the build environment
before_install:
    # Get the Fatiando CI scripts
    - git clone --branch=1.2.0 --depth=1 https://github.com/fatiando/continuous-integration.git
    # Download and install miniconda and setup dependencies
    # Need to source the script to set the PATH variable globaly
    - source continuous-integration/travis/setup-miniconda.sh
    # Show installed pkg information for postmortem diagnostic
    - conda list

# Install the package that we want to test
install:
    # Make a binary wheel for our package and install it
    - python setup.py bdist_wheel
    - pip install dist/*

# Run the actual tests and checks
script:
    # Run the test suite
    - make test
    # Build the documentation
    - make -C doc clean all

# Things to do if the build is successful
after_success:
    # Upload coverage information
    - coverage xml
    - echo "Uploading coverage to Codecov"
    - codecov -e PYTHON

# Deploy
deploy:
    # Make a release on PyPI
    - provider: script
      script: continuous-integration/travis/deploy-pypi.sh
      on:
          tags: true
          condition: '$DEPLOY_PYPI == "true"'
    # Push the built HTML in doc/_build/html to the gh-pages branch
    - provider: script
      script: continuous-integration/travis/deploy-gh-pages.sh
      skip_cleanup: true
      on:
          branch: master
          condition: '$DEPLOY_DOCS == "true"'
    # Push HTML when building tags as well
    - provider: script
      script: continuous-integration/travis/deploy-gh-pages.sh
      skip_cleanup: true
      on:
          tags: true
          condition: '$DEPLOY_DOCS == "true"'

# Don't send out emails every time a build fails
notifications:
    email: false
